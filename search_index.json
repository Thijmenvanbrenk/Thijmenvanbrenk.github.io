[["index.html", "Thijmens portfolio Chapter 1 Introduction 1.1 Personality 1.2 Reproducability 1.3 Extra skills", " Thijmens portfolio Thijmen van Brenk 2022-05-31 Chapter 1 Introduction Welcome to my portfolio In this github page I will show what I have learned in the past 5 months. On the left side you can see different subjects i have worked on, you can easily access them by clicking on them. If you want to know what every section entails, without having to click every one of them, there is a description of every section below. 1.1 Personality  CV: in this section you can find my CV with my education and work skills. (in dutch) 1.2 Reproducability In the reproducability section I will be handling topics that have to do with open science and reproducability.  Reproducing skills: in this section you can see how i used a dataset from a published paper and how i was able to reproduce their results.  Grading reproducability: in this section you see how i graded a paper on the criteria for reproducability and the code from another paper was graded on readability and reproducability.  Organization: in this section you can see how i have stored my files for a previous project. 1.3 Extra skills In the extra skills section I will be showing you some of my extra skills like different programming languages.  Using references: In this section you can see how i have written an introduction using multiple references.  Using parameters: in this section you can see how i made use of multiple parameter settings to make graph making easier. "],["personality-1.html", "Chapter 2 Personality 2.1 CV", " Chapter 2 Personality 2.1 CV Below you can see my CV Because making the CV uses special headers its not possible to knit it into bookdown, thats why this is just the picture of the CV. the orginal code can be found in this repository at: data/CV_thijmenvanbrenk.Rmd "],["reproducability-1.html", "Chapter 3 Reproducability 3.1 Reproducing data from a published paper 3.2 Checking reproducability for published papers. 3.3 organisation of my files", " Chapter 3 Reproducability 3.1 Reproducing data from a published paper Here i am showing you how i am able to reproduce results from a published paper the data used in this assignment comes from (van der Voet et al. 2021) library(tidyverse) library(here) library(readxl) library(rbbt) library(RColorBrewer) offspring &lt;- read_excel(here(&quot;data/CE.LIQ.FLOW.062_Tidydata.xlsx&quot;), sheet = 1) # we want to see if the data for the experimental conditions have been imported correctly offspring %&gt;% select(c(&quot;expType&quot;, &quot;RawData&quot;, &quot;compName&quot;, &quot;compConcentration&quot;)) ## # A tibble: 360 x 4 ## expType RawData compName compConcentration ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 experiment 44 2,6-diisopropylnaphthalene 4.99 ## 2 experiment 37 2,6-diisopropylnaphthalene 4.99 ## 3 experiment 45 2,6-diisopropylnaphthalene 4.99 ## 4 experiment 47 2,6-diisopropylnaphthalene 4.99 ## 5 experiment 41 2,6-diisopropylnaphthalene 4.99 ## 6 experiment 35 2,6-diisopropylnaphthalene 4.99 ## 7 experiment 41 2,6-diisopropylnaphthalene 4.99 ## 8 experiment 36 2,6-diisopropylnaphthalene 4.99 ## 9 experiment 40 2,6-diisopropylnaphthalene 4.99 ## 10 experiment 38 2,6-diisopropylnaphthalene 4.99 ## # ... with 350 more rows # as we can see, the rawdata should have been an integer, the compname and expType should have been a factor and the compconcentration should have been a double. lets change that offspring$RawData &lt;- as.integer(offspring$RawData) offspring$compName &lt;- as.factor(offspring$compName) offspring$expType &lt;- as.factor(offspring$expType) offspring_tidy &lt;- offspring offspring_tidy$compConcentration &lt;- as.numeric(offspring_tidy$compConcentration) # one of the values in compconcentration is accidentally classified as a character in excel and has now turned into a NA value, we will change this value manually. character_placement &lt;- which(is.na(offspring_tidy$compConcentration)) character_value &lt;- offspring$compConcentration[character_placement] %&gt;% str_replace(&quot;,&quot;, &quot;.&quot;) %&gt;% parse_number() offspring_tidy$compConcentration[character_placement] &lt;- character_value # lets check one last time if the data types are correct. offspring %&gt;% select(c(&quot;RawData&quot;, &quot;compName&quot;, &quot;compConcentration&quot;)) ## # A tibble: 360 x 3 ## RawData compName compConcentration ## &lt;int&gt; &lt;fct&gt; &lt;chr&gt; ## 1 44 2,6-diisopropylnaphthalene 4.99 ## 2 37 2,6-diisopropylnaphthalene 4.99 ## 3 45 2,6-diisopropylnaphthalene 4.99 ## 4 47 2,6-diisopropylnaphthalene 4.99 ## 5 41 2,6-diisopropylnaphthalene 4.99 ## 6 35 2,6-diisopropylnaphthalene 4.99 ## 7 41 2,6-diisopropylnaphthalene 4.99 ## 8 36 2,6-diisopropylnaphthalene 4.99 ## 9 40 2,6-diisopropylnaphthalene 4.99 ## 10 38 2,6-diisopropylnaphthalene 4.99 ## # ... with 350 more rows # they are so we can now use the data for further analysis offspring_tidy %&gt;% ggplot(aes(x = log10(compConcentration + 0.0001), y = RawData)) + geom_jitter(aes(shape = expType, colour = compName), width = .1) + labs(title = &quot;Amount of offspring from C. elegans incubated in different substances&quot;, subtitle = &quot;Experiment data from (van der Voet et al. 2021)&quot;, x = &quot;Log 10 of compound concentration&quot;, y = &quot;Amount of offspring per C. elegans&quot;, colour = &quot;Compound name&quot;, shape = &quot;Experiment type&quot;) + scale_shape_discrete(labels = c(&quot;Negative control&quot;, &quot;Positive control&quot;, &quot;Vehicle A control&quot;, &quot;Experiment&quot;)) + scale_colour_brewer(palette = &quot;Dark2&quot;) + theme_classic() the positive control of this experiment is Ethanol and the negative control is no added substance. to analyze this experiment I would follow these steps. 1. making a new column which shows which condition every worm is located in. (for example, group1 would consist of 2,6-diisopropylnaphthalene with a concentration of 4.99 nM, etc.) 2. checking normality for every condition. NORMALLY DISTRIBUTED DATA: 3. perform ANOVA. with post-hoc tests and check if they differ from the control. NOT NORMALLY DISTRIBUTED DATA: 3. perform kruskal - wallis test. 4. to visualize this difference, make a smoothed line graph for every the mean of every concentration per substance. 5. compare these graphs with each other. normalized_value &lt;- offspring_tidy %&gt;% group_by(compName) %&gt;% filter(compName == &quot;S-medium&quot;) %&gt;% summarise(mean = mean(RawData, na.rm = T)) offspring_tidy &lt;- offspring_tidy %&gt;% mutate(normalized_offspring = RawData/normalized_value$mean) offspring_tidy %&gt;% ggplot(aes(x = log10(compConcentration + 0.0001), y = normalized_offspring)) + geom_jitter(aes(shape = expType, colour = compName), width = .1) + labs(title = &quot;Amount of offspring from C. elegans incubated in different substances&quot;, subtitle = &quot;Experiment data from (van der Voet et al. 2021)&quot;, x = &quot;Log 10 of compound concentration&quot;, y = &quot;Normalized offspring amount by mean of negative control&quot;, colour = &quot;Compound name&quot;, shape = &quot;Experiment type&quot;) + scale_shape_discrete(labels = c(&quot;Negative control&quot;, &quot;Positive control&quot;, &quot;Vehicle A control&quot;, &quot;Experiment&quot;)) + scale_colour_brewer(palette = &quot;Dark2&quot;) + theme_classic() We normalize the data so we can see the difference between the different substances more easily. 3.2 Checking reproducability for published papers. in this assignment, this study (Strobl et al. 2020) will be graded on the criteria for reproducibility. and this study (Brewer, Robey, and Unsworth 2021) will be graded on code readability and reproducibility. 3.2.1 Pesticide influence on consumption rate and survival for bees. introduction of the paper the use of pesticides is one of the main reasons of loss of biodiversity, and the combination of multiple pesticides could even make this worse. in this experiment it is investigated what the sublethal (food consumption) and the lethal (survival) effects of pesticides are on adult female solitary bees, Osmia bicornis. to perform these tests, female solitary bees were divided into 4 groups:  pesticide free (control)  herbicide  pesticide  combined (both herbicide and pesticide) their consumption rate and longevity were measured and the data from these two variables are used for analysis. there is no significant difference in survival and consumption between te different groups. there is however a significant positive correlation between the consumption rate and the longevity of these bees. transparancy criteria grading transparancycriteria grading study purpose TRUE dataavailability FALSEonly part of the data isavailable data location at the beginning/at the end studylocation TRUEmaterials/methods authorreview location and emailare present at the top ethicsstatement FALSE fundingstatement TRUE codeavailability TRUE The part of the data that is available can be accessed through this directory: data/insects-957898-supplementary.xlsx 3.2.2 impact of analysis decisions for episodic memory and retrieval practices. we will solely focus on the code of this paper to see:  If the code can be understood easily.  If I can reproduce one of the figures.  If there are any bugs/flaws in the code. the code is available in this website the code has been copied to a new Rmd file in this repository under the name _analysis_decisions_code.Rmd the data has been downloaded and is available in this repository under the name data/AllDataRR.csv changes made:  changed the directory in line 11 so it retrieved the data used from this study.  installed the packages in line 19 and line 180. first impression:  (+) every test is in different chunks which makes readability easier.  (+) clear comments on what is happening.  (+) easy to understand code  (-) chunks dont have names.  (-) the individual results are far away from each other.  (-) the same tests are set of tests are performed multiple times, making a function would make chances of mistakes less likely what this code is trying to achieve the first part of the code for this experiment is looking for the correlation between individual and different studies (line 24-174) the second part of the code for this experiment is looking at a correlation between the retrieval practice effect and the EM ability with the help of a graph. there are 2 graphs, one where everything is mean centered and one where it isnt. final judgement: (grading goes from 1-5(1 very hard/bad- 5 very easy/good))  readability = 4  reproducability = 5  efficiency = 2 3.3 organisation of my files to show my ability at organizing files heres an example of the file structure from one of my previous projects References "],["extra-skills-1.html", "Chapter 4 Extra skills 4.1 Writing an introduction using Zotero for references 4.2 creating paramaters for different data inputs", " Chapter 4 Extra skills In this section of my portfolio i will show you some of the extra skills I have developed during my data science minor. 4.1 Writing an introduction using Zotero for references Writing research papers is a pretty important for the research field, so using references to other papers is crucial for writing a good introduction. below here you can see an introduction to my project about liquid biopsies, it makes use of multiple references. Neuroblastoma is the fourth most common tumor in children and presents itself as either a low-risk neuroblastoma or a high-risk neuroblastoma. determining which risk neuroblastoma is present a tumor biopsy is necessary. (Weiser et al. 2019) however these biopsies are very invasive and can only be done a few times even tho the tumor keeps mutating. to counter this problem researchers have become more and more interested in liquid biopsies to be able to track the mutations in the tumor. this is possible because the tumor often excretes DNA into the blood stream which is then used for whole-exome sequencing (WES). these results can be compared with the DNA of the tumor to show how the tumor evolves over time (Chicard et al. 2018). because the tumor cells have different properties depending on what part of the tumor they are on it is difficult to show all the mutations based on 1 tumor biopsy as that can have a bias for only that specific part of the tumor where the biopsy was taken from. liquid biopsies also help with this problem as they sequence all the DNA that has been excreted by the tumor, this makes it possible to spot different mutations in both tumor DNA and cell free DNA (cf-DNA). (Van Paemel et al. 2022) The type of mutations that get the most attention are the copy number variations/aberrations (CNV/CNA) these CNVs can either be very small with just a few kilobases or very big where they cover the whole chromosome. the CNVs are very importants as they can give an identification on how pathogenic the tumor is based on the genes it contains, the position of the CNV and the size of the CNV (Riggs et al. 2020). Some hospitals sadly dont have easy ways to analyse the data from all these patients because they do not have the experience with data analysis. this makes the process of analyzing the data a slow and tedious task. even tho it would be extremely beneficial for the hospitals without data scientists to have the programs available to analyse these results quickly (Valsesia et al. 2013), this takes away the time consuming task of having to analyze every file manually which gives them time to focus on more important things like treating the patient. sharing these results to other hospitals is equally as important because there is not nearly enough data available to say with certainty how dangerous certain tumors are and if the tumors have been fully removed. With all the data combined the research towards liquid biopsies can evolve quickly making diagnoses easier and more reliable In this project we will analyse the tumor DNA and the cfDNA created by WES and will make it reproducible so that Princess maxima centre can easily analyse the data for all their patients. to accomplish this we will mostly focus on:  giving all the CNVs different IDs so they can be easily distinguished from each other.  showing which cytogenetic band the CNV falls in to.  making an interactive plot to look up genes easily.  automatically filtering genes that indicate high risk neuroblastomas.  making a high throughput version so that it will analyse multiple datasets at the same time without having to manually insert all the data sets  getting these results quickly and easily so the researcher does not have to focus on how to analyze the data. 4.2 creating paramaters for different data inputs to show my ability to use paramaters I will be using data from the ECDC. the data is available in this repository under data/COVID_cases_31_05_2022 # loading in data cases &lt;- read.csv(&quot;data/COVID_cases_31_05_2022.csv&quot;) # filtering the params used cases_filtered &lt;- cases %&gt;% dplyr::filter(countriesAndTerritories == params$country, year == params$year, month &gt;= params$period_start, month &lt;= params$period_end) # telling R the dateRep column is a date cases_filtered$dateRep &lt;- as.Date(cases_filtered$dateRep, format = &quot;%d/%m/%Y&quot;) # making a graph for cases cases_graph &lt;- cases_filtered %&gt;% ggplot(aes(x = dateRep, y = cases)) + geom_point(size = .5) + geom_line() + labs(title = paste(&quot;Covid related cases from month&quot;, params$period_start, &quot;to&quot;, params$period_end, &quot;in&quot;, params$year, &quot;for&quot;, params$country), x = &quot;Month&quot;, y = &quot;Covid related cases&quot;) + theme_classic() ggplotly(cases_graph) # making a graph for deaths deaths_graph &lt;- cases_filtered %&gt;% ggplot(aes(x = dateRep, y = deaths)) + geom_point(size = .5) + geom_line() + labs(title = paste(&quot;Covid related deaths from month&quot;, params$period_start, &quot;to&quot;, params$period_end, &quot;in&quot;, params$year, &quot;for&quot;, params$country), x = &quot;Month&quot;, y = &quot;Covid related deaths&quot;) + theme_classic() ggplotly(deaths_graph) If you want to recreate these graphs with different params clone this repository and use put this command in the console (with your own params ofcourse): bookdown::render_book(params = list(country = &quot;Netherlands&quot;, year = 2021, period_start = 5, period_end = 10)) References "],["references.html", "Chapter 5 References", " Chapter 5 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
